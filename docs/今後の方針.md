# Retento 学習体験設計メモ（LLM・メンター構想まとめ）

## 0. 前提・ゴール

- 対象：大学受験レベル／共通テスト・英検準1級など
- コア体験：
  - アプリを開いた瞬間に**即学習開始**（メニュー経由なし）
  - 文中の下線部（英単語）の意味を問う4択形式
  - 例文の文脈から意味を推測する、共テ的読解スタイルを重視
- プロダクトの核：
  - **UX最優先**（ストレスフリー・ノイズのない流れ）
  - 「学習をずっと見守る高次の存在（メンターAI）」が裏にいる世界観
  - ただし学生向けなので**コストは極限まで抑えたい**

---

## 1. 問題・解説生成の基本方針

### 1-1. オンライン生成ではなく「事前生成バンク」方式

- 毎回 nano / mini に投げて問題＋解説を生成させるのは
  - 品質が足りない
  - コストも蓄積すると重い
- 解決策：
  - **GPT-5（高性能モデル）でオフライン一括生成**
  - 単語ごとに 10 パターン程度の「完成した問題」を作る

### 1-2. 1問の構造イメージ

- 英文例文（10〜15語、該当単語だけ `<u>`）
- 例文の自然な和訳
- 日本語4択（正解＋紛らわしい誤答3つ）
- 各選択肢についての丁寧な解説（語源・ニュアンス・類義語との違いなど）
- メタ情報：
  - `difficulty_score`（既存）
  - `tags`（意味領域：science / abstract_emotion / etc.）
  - `usage_scene`（どんな場面の文か）
  - embedding 用のテキスト素材

> 解説は「1例文につき1パターン」でよい。  
> 例文と解説は一心同体の“完成品”として扱う。

### 1-3. 「同じ問題が出ない」の扱い

- 単語ごとに十分なバリエーション（10問程度）
- `sentence` × `wrongChoices` の組合せだけでもバリエーションが出る
- 完全に一度も重ならないのは難しいが、
  - 「同じ問題が連続して出ない」
  - 「しばらくは別バリエーションを優先」
  のような運用でLPのメッセージと整合性をとる方向

---

## 2. SRS・出題ロジックとパーソナライズ

### 2-1. LLMではなくアルゴリズムでやるべき領域

ここは**ガチ数式・ロジック担当**。

- 忘却曲線・SRSロジック
  - 単語ごとの next_due
  - ユーザー別の実効難易度（difficulty_scoreを動的に補正）
- 出題候補の決定：
  - 原則：**「今日〜近い将来にdueの単語」から選ぶ**
- 偏り防止：
  - 各単語に `global_seen_count` を持ち、出現頻度の偏りを補正
  - タグ別の出題率が極端にならないように調整

> 「どの単語を**宇宙として候補にするか**」は、  
> SRS＋統計でガチガチに決める。  
> メンターAIは、その宇宙の中で**重み付けを変えるだけ**。

### 2-2. パラメトリックなパーソナライズ

LLMで「問題を作り替える」のではなく、  
**「出題エンジンの設定」をユーザーごとに持つ**。

例：

```jsonc
{
  "target_difficulty_center": 0.55,
  "difficulty_spread": 0.15,
  "new_to_review_ratio": 0.3,
  "focus_clusters": ["abstract_emotion", "academic_essay"],
  "avoid_clusters": ["very_easy_daily"],
  "mistake_pattern_focus": ["degree_adjectives", "abstract_nouns"],
  "exam_mode_bias": "center_exam",
  "session_length": 5
}
````

* これは純粋に数値／ラベルなので**LLM不要**で扱える
* メンターAIはこのJSONを「会話を通じて編集する係」

---

## 3. テーマ性・文脈性のあるセッションの実現（embedding）

### 3-1. embedding の役割

* 各問題に対して embedding を計算して保存：

  * 英文
  * 正解の和訳
  * tags / usage_scene などを連結したテキスト
* セッション作成時：

  1. SRSで「dueな単語候補」が出る
  2. その中から1問目を選ぶ
  3. 1問目の embedding をキーに、類似問題を検索
  4. 類似度が高く、未出題のものを中心に 4問選んで「5問セット」を構成

→ **意味的に近い問題で固めたテーマセッション**を、
LLMなしで実現できる。

### 3-2. 得意・苦手分野の統計

タグごとに：

* 出題数 / 正答数 / 平均difficulty / 平均反応時間

を集計することで、

* 得意なクラスタ
* 苦手なクラスタ
* 「difficultyの割にミスが多い＝誤解が多い」領域

などを全て**数値で**把握できる。

これを出題パラメータの `focus_clusters` / `avoid_clusters` に反映。

---

## 4. メンターAIの設計

### 4-1. 立ち位置

* 「ずっと学習を見ている高次の存在」
* ただし：

  * 通常の学習フローには**割り込まない**
  * あくまで「ときどき相談しに行く」存在
* Retento 本体：

  * 起動 → 即4択問題
* メンターモード（別画面）：

  * 週1セッション程度
  * 3往復×200文字程度など、**長さに制限**を設ける

### 4-2. モデルの役割分担

* メンター本人（対話）：

  * GPT-5 クラス（ちゃんと賢くあってほしい部分）
  * 仕事：

    * 学習傾向のフィードバック
    * ユーザーの希望・不安のヒアリング
    * 出題パラメータJSONの編集・提案
* 要約・プロファイル更新：

  * nano / mini クラスで十分
  * 仕事：

    * メンターチャット1セッション分を要約
    * 既存 `mentor_profile` を更新（圧縮された長期記憶）

### 4-3. `mentor_profile`（長期記憶）のイメージ

ユーザーごとに1つだけ持つ、小さなJSON：

```jsonc
{
  "userId": "u123",
  "strengthClusters": [...],
  "weaknessClusters": [...],
  "errorPatterns": [
    "程度差の形容詞で混乱しやすい",
    "抽象名詞＋動詞のコロケーションが弱い"
  ],
  "learningStyle": {
    "riskTaking": "high",
    "prefersContext": "yes",
    "notes": "例文から推測する場面は得意だが、早とちりしがち。"
  },
  "longTermGoals": ["共通テスト英語8割", "英検準1級合格"],
  "mentorNotes": "最近は疲れているのか、易しめの単語でもケアレスミスが増えた。次のセッションでは成功体験を意図的に増やしたい。",
  "lastUpdatedAt": "..."
}
```

* 毎回のメンターチャット終了時に、
  軽量モデルでこのプロファイルを**上書き更新**していく。
* LLMに渡すコンテキストは

  * 固定の短い system
  * `mentor_profile`
  * 今回の会話の過去メッセージ（最大3往復程度）
    のみで済む。

### 4-4. メンターチャットのライフサイクル

1. ユーザーが「メンターと話す」を選ぶ
2. GPT-5 に：

   * system（人格＋役割）
   * `mentor_profile`
   * ユーザーの発話
     を渡して会話開始
3. 3往復程度で区切り：

   * 「今日はこのくらいにしましょう」と自然に締める
4. 終了時：

   * 会話ログ＋旧 `mentor_profile` を nano に渡し、
   * 新しい `mentor_profile` を生成して保存

→ **無限コンテキストではなく**
「プロフィール＋要約＋必要ならembedding検索」で“覚えている感”を出す。

---

## 5. メンター利用制限と料金感

* 無料ユーザー：

  * メンターモードは「お試し1回」などに制限
* 有料ユーザー：

  * 週1セッションまで（3往復×200字程度）
* 超ヘビー向けプラン：

  * 週2〜3セッション、FlexiStudy等との統合メンターへ拡張…など将来案

**ポイント：**

* メンターの「顔」は GPT-5でしっかり作る
* コストは頻度と長さで管理
* 要約や内部アップデートは超軽量モデルに任せる

---

## 6. 「MVPではなく、薄くても完成されたUX」の方針

* 一般的な「雑なMVP」ではなく、

  * **機能範囲は狭くてよいが、その範囲はちゃんと気持ちよく動く**形を目指す
* 初期スコープ案（例）：

  1. 対応試験を「共通テスト＋英検準1級程度」に絞る
  2. 単語あたり 5〜10 問の高品質バンクを GPT-5で生成
  3. SRS＋タグ＋embedding に基づくテーマセッション
  4. メンターモード：

     * 週1回
     * 学習傾向のフィードバック＋2〜3パラメータの調整
     * 体験としての完成度を優先

> 「UI」ではなく**「UX（流れ＋意味＋感情）」**が主戦場。
>
> LLMはあくまで
>
> * 教材を書くクリエイター
> * 数値プロファイルを“言葉に翻訳する存在”
>   として使い、
>   学習効果とコストを支える土台は**アルゴリズムとデータ設計**で固める。